# Hi, I'm Rahul Kadam.

I am an **ML Systems Engineer** focused on the infrastructure layer of AI. I bridge the gap between model architecture and hardware constraints, optimizing for training latency, memory efficiency, and scale.

### üî≠ Engineering Focus
*   **Distributed Training:** Architecting multi-GPU training loops using **DeepSpeed (ZeRO)** and **PyTorch DDP**.
*   **High-Performance Computing:** Building low-level **C++** simulators and optimizing kernels for **CUDA**.
*   **Production MLOps:** Contributor to **Opik** (Open Source), building evaluation pipelines with CI/CD integration.

### üöÄ Highlighted Projects

| Project | Tech Stack | Impact |
| :--- | :--- | :--- |
| **[Distributed LLM Training](https://github.com/kadamrahul18/GPT2-Optimization)** | PyTorch, DeepSpeed, AWS | Reduced GPT-2 training time by **72%** and memory usage by **50%** via ZeRO-2. |
| **[MIPS Processor Simulator](https://github.com/CSA-Labs/mips-pipelined)** | C++, Linux, Make | Built a cycle-accurate 5-stage pipeline with hazard detection and forwarding logic. |
| **[Opik LLM Eval Platform](https://github.com/comet-ml/opik)** | Python, Docker, Pytest | Shipped core LLM quality scoring features and unit tests for a major open-source tool. |
| **[Medical Image Segmentation](https://github.com/kadamrahul18/Classification-of-MRI-images-for-Brain-Tumor-Using-Convolutional-Neural-Networks)** | TensorFlow, GCP, Docker | Deployed U-Net inference service on GCP Vertex AI for brain tumor segmentation. |

### üõ†Ô∏è Tech Stack
*   **Systems:** C++, CUDA, Bash, Linux
*   **ML Infrastructure:** PyTorch (DDP), DeepSpeed, Triton, Docker, Kubernetes
*   **Cloud:** AWS (EC2, Multi-node), GCP (Vertex AI)

[<img src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" />](https://www.linkedin.com/in/rahul-kadam6399/)
